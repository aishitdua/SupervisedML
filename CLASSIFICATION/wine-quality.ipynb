{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('winequality-white.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    2198\n",
       "5    1457\n",
       "7     880\n",
       "8     175\n",
       "4     163\n",
       "3      20\n",
       "9       5\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['quality'].value_counts() # no of instances in each value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
       "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
       "       'pH', 'sulphates', 'alcohol', 'quality'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
    "       'pH', 'sulphates', 'alcohol']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['quality'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.72096961e-01, -8.17699008e-02,  2.13280202e-01,\n",
       "         2.82134917e+00, -3.53550004e-02,  5.69931577e-01,\n",
       "         7.44565035e-01,  2.33151201e+00, -1.24692128e+00,\n",
       "        -3.49184257e-01, -1.39315246e+00],\n",
       "       [-6.57501128e-01,  2.15895632e-01,  4.80011213e-02,\n",
       "        -9.44765273e-01,  1.47747079e-01, -1.25301866e+00,\n",
       "        -1.49684624e-01, -9.15417164e-03,  7.40028640e-01,\n",
       "         1.34184656e-03, -8.24275678e-01],\n",
       "       [ 1.47575110e+00,  1.74519434e-02,  5.43838363e-01,\n",
       "         1.00282190e-01,  1.93522599e-01, -3.12141119e-01,\n",
       "        -9.73335626e-01,  3.58664800e-01,  4.75101984e-01,\n",
       "        -4.36815783e-01, -3.36667007e-01],\n",
       "       [ 4.09124986e-01, -4.78657278e-01, -1.17277959e-01,\n",
       "         4.15768217e-01,  5.59726758e-01,  6.87541270e-01,\n",
       "         1.12109121e+00,  5.25855242e-01,  1.14803354e-02,\n",
       "        -7.87341887e-01, -4.99203231e-01],\n",
       "       [ 4.09124986e-01, -4.78657278e-01, -1.17277959e-01,\n",
       "         4.15768217e-01,  5.59726758e-01,  6.87541270e-01,\n",
       "         1.12109121e+00,  5.25855242e-01,  1.14803354e-02,\n",
       "        -7.87341887e-01, -4.99203231e-01]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocessing for knn algorithm\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X.astype(float)) # we standardize the data i.e. center it around zero\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3918, 11), (980, 11))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the network\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64591837, 0.57346939, 0.54591837, 0.54897959, 0.54897959,\n",
       "       0.53061224, 0.5377551 , 0.54489796, 0.53265306, 0.54285714,\n",
       "       0.55510204, 0.54795918, 0.54285714, 0.53367347, 0.53469388,\n",
       "       0.53469388, 0.5244898 , 0.53571429, 0.54183673, 0.53979592,\n",
       "       0.53877551, 0.54795918, 0.54795918, 0.54795918, 0.54897959,\n",
       "       0.54591837, 0.5377551 , 0.53673469, 0.53877551, 0.55      ,\n",
       "       0.54183673, 0.54795918, 0.54795918, 0.55408163, 0.54693878,\n",
       "       0.55714286, 0.54795918, 0.55408163, 0.54387755, 0.54285714,\n",
       "       0.53571429, 0.54285714, 0.54489796, 0.53979592, 0.53877551,\n",
       "       0.54591837, 0.54591837, 0.54489796, 0.54795918, 0.54387755,\n",
       "       0.54183673, 0.54183673, 0.54081633, 0.5377551 , 0.53979592,\n",
       "       0.53877551, 0.53979592, 0.5377551 , 0.54387755, 0.54183673,\n",
       "       0.54489796, 0.54693878, 0.54387755, 0.53877551, 0.54081633,\n",
       "       0.53673469, 0.53979592, 0.53979592, 0.54081633, 0.53877551,\n",
       "       0.52959184, 0.52755102, 0.52653061, 0.52653061, 0.52346939,\n",
       "       0.52959184, 0.5244898 , 0.52040816, 0.52653061, 0.52959184,\n",
       "       0.52346939, 0.52755102, 0.53061224, 0.53061224, 0.53265306,\n",
       "       0.53163265, 0.53469388, 0.53367347, 0.53571429, 0.53367347,\n",
       "       0.53673469, 0.53571429, 0.53367347, 0.53571429, 0.53673469,\n",
       "       0.53673469, 0.53367347, 0.53571429, 0.53571429, 0.53265306,\n",
       "       0.52857143, 0.53367347, 0.53265306, 0.53265306, 0.52959184,\n",
       "       0.53163265, 0.52755102, 0.52857143, 0.52653061, 0.52755102,\n",
       "       0.53061224, 0.53469388, 0.53163265, 0.53163265, 0.53061224,\n",
       "       0.53061224, 0.53265306, 0.53367347, 0.53367347, 0.53469388,\n",
       "       0.53265306, 0.53571429, 0.53673469, 0.53673469, 0.53571429,\n",
       "       0.54081633, 0.53877551, 0.53469388, 0.5377551 , 0.53469388,\n",
       "       0.53469388, 0.53367347, 0.53877551, 0.53571429, 0.53877551,\n",
       "       0.53469388, 0.53265306, 0.53061224, 0.53265306, 0.53265306,\n",
       "       0.53367347, 0.52959184, 0.52857143, 0.52346939, 0.5244898 ,\n",
       "       0.5255102 , 0.52346939, 0.5255102 , 0.52857143, 0.52755102,\n",
       "       0.52653061, 0.52244898, 0.52142857, 0.52346939, 0.51938776,\n",
       "       0.52142857, 0.52040816, 0.52040816, 0.52346939, 0.52346939,\n",
       "       0.52040816, 0.5244898 , 0.52040816, 0.5244898 , 0.5244898 ,\n",
       "       0.52040816, 0.51836735, 0.51938776, 0.51938776, 0.51734694,\n",
       "       0.52142857, 0.51530612, 0.51632653, 0.51428571, 0.51326531,\n",
       "       0.5122449 , 0.51326531, 0.51632653, 0.51428571, 0.51836735,\n",
       "       0.51632653, 0.51938776, 0.52142857, 0.52142857, 0.52244898,\n",
       "       0.52244898, 0.51836735, 0.52142857, 0.52142857, 0.52142857,\n",
       "       0.52244898, 0.52346939, 0.52040816, 0.52040816, 0.51836735,\n",
       "       0.51836735, 0.51632653, 0.51938776, 0.51530612, 0.51734694,\n",
       "       0.51836735, 0.51836735, 0.51836735, 0.51938776, 0.51734694,\n",
       "       0.51938776, 0.51938776, 0.51836735, 0.51632653, 0.51632653,\n",
       "       0.51632653, 0.51938776, 0.52040816, 0.51632653, 0.51734694,\n",
       "       0.51632653, 0.52040816, 0.51734694, 0.51632653, 0.51734694,\n",
       "       0.51734694, 0.51836735, 0.51734694, 0.51632653, 0.51734694,\n",
       "       0.51632653, 0.51836735, 0.52040816, 0.51938776, 0.52040816,\n",
       "       0.51938776, 0.51836735, 0.52040816, 0.52142857, 0.51836735,\n",
       "       0.52244898, 0.52346939, 0.52142857, 0.51836735, 0.51836735,\n",
       "       0.51938776, 0.51836735, 0.51836735, 0.51938776, 0.51938776,\n",
       "       0.51632653, 0.51836735, 0.51734694, 0.51938776, 0.51836735,\n",
       "       0.51734694, 0.51734694, 0.51836735, 0.51734694, 0.51938776,\n",
       "       0.52040816, 0.51938776, 0.51836735, 0.51938776, 0.51836735,\n",
       "       0.51734694, 0.51632653, 0.51734694, 0.51326531, 0.5122449 ,\n",
       "       0.51632653, 0.51326531, 0.51632653, 0.51326531, 0.51632653,\n",
       "       0.51122449, 0.5122449 , 0.50918367, 0.51020408, 0.50918367,\n",
       "       0.50918367, 0.50918367, 0.50816327, 0.50714286, 0.50612245,\n",
       "       0.50714286, 0.50510204, 0.50612245, 0.50510204, 0.50612245,\n",
       "       0.50510204, 0.50510204, 0.50714286, 0.50612245, 0.50612245,\n",
       "       0.49795918, 0.50306122, 0.49693878, 0.5       , 0.5       ,\n",
       "       0.50204082, 0.50102041, 0.50306122, 0.50102041, 0.50204082,\n",
       "       0.50204082, 0.49897959, 0.49795918, 0.5       , 0.5       ,\n",
       "       0.50306122, 0.50306122, 0.50306122, 0.50204082, 0.50102041,\n",
       "       0.50102041, 0.50102041, 0.50204082, 0.5       , 0.50408163,\n",
       "       0.50102041, 0.50204082, 0.50408163, 0.50204082, 0.50510204,\n",
       "       0.50408163, 0.50408163, 0.50204082, 0.50816327, 0.50918367,\n",
       "       0.50714286, 0.50816327, 0.50612245, 0.50408163, 0.50612245,\n",
       "       0.50714286, 0.50408163, 0.50714286, 0.50612245, 0.50408163,\n",
       "       0.50306122, 0.50408163, 0.50306122, 0.50510204, 0.50612245,\n",
       "       0.50510204, 0.50306122, 0.50408163, 0.50306122, 0.50612245,\n",
       "       0.50816327, 0.50714286, 0.50510204, 0.50510204, 0.50714286,\n",
       "       0.50408163, 0.50204082, 0.50204082, 0.50612245, 0.51122449,\n",
       "       0.51632653, 0.51734694, 0.51122449, 0.51122449, 0.50918367,\n",
       "       0.50918367, 0.5122449 , 0.50918367, 0.51020408, 0.51122449,\n",
       "       0.50918367, 0.50816327, 0.5122449 , 0.50510204, 0.50102041,\n",
       "       0.50306122, 0.50510204, 0.50612245, 0.50816327, 0.50510204,\n",
       "       0.50612245, 0.50306122, 0.50306122, 0.50612245, 0.50510204,\n",
       "       0.50204082, 0.50714286, 0.50612245, 0.51020408, 0.50918367,\n",
       "       0.5122449 , 0.51020408, 0.51020408, 0.5122449 , 0.50918367,\n",
       "       0.51020408, 0.50816327, 0.51020408, 0.51326531, 0.51122449,\n",
       "       0.51326531, 0.51428571, 0.51122449, 0.51326531])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ks = 400\n",
    "mean_acc = np.zeros((Ks-1))\n",
    "std_acc = np.zeros((Ks-1))\n",
    "ConfustionMx = [];\n",
    "for n in range(1,Ks):\n",
    "    \n",
    "    #Train Model and Predict  \n",
    "    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n",
    "    yhat=neigh.predict(X_test)\n",
    "    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n",
    "\n",
    "    \n",
    "    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n",
    "\n",
    "mean_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression #liblinear is good for small binary classfication datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "LR = LogisticRegression(C=0.01, solver='liblinear')\n",
    "LR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 7, 6, 6, 6, 6, 5, 6, 6, 5, 6, 5, 6, 6, 6, 5, 6, 6, 6, 5, 6, 6,\n",
       "       5, 6, 6, 6, 5, 6, 5, 5, 5, 6, 5, 5, 5, 6, 6, 5, 5, 6, 6, 5, 6, 6,\n",
       "       5, 6, 5, 5, 6, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 5, 6, 6, 6,\n",
       "       6, 5, 6, 5, 5, 6, 5, 5, 6, 6, 6, 6, 6, 6, 5, 5, 6, 6, 6, 6, 5, 6,\n",
       "       6, 6, 6, 5, 5, 6, 6, 6, 6, 6, 5, 6, 5, 6, 6, 5, 6, 6, 5, 6, 6, 6,\n",
       "       6, 6, 6, 5, 5, 6, 6, 6, 6, 6, 5, 6, 6, 5, 6, 6, 7, 6, 6, 5, 6, 6,\n",
       "       6, 6, 5, 6, 6, 5, 6, 5, 6, 6, 6, 5, 6, 5, 5, 6, 5, 6, 6, 6, 6, 6,\n",
       "       6, 5, 6, 6, 6, 5, 6, 5, 6, 5, 6, 6, 5, 6, 5, 6, 5, 6, 6, 6, 6, 6,\n",
       "       5, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 5, 6, 5, 5, 6, 6, 6, 5, 6, 6, 6,\n",
       "       5, 6, 6, 5, 6, 6, 6, 6, 7, 6, 6, 6, 5, 6, 6, 6, 5, 6, 5, 5, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 5, 6, 5, 5, 7, 6, 6, 6, 6, 6, 5,\n",
       "       7, 6, 6, 6, 6, 5, 6, 5, 6, 6, 6, 5, 6, 5, 6, 5, 6, 6, 6, 5, 6, 5,\n",
       "       6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 5, 6, 6, 6, 5, 5, 6,\n",
       "       6, 5, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 5, 6, 5, 5, 6, 6, 7, 6, 5, 6,\n",
       "       6, 6, 6, 5, 5, 6, 6, 7, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 5, 6, 5, 6, 6, 5, 6, 6, 6, 6,\n",
       "       6, 5, 6, 5, 6, 6, 6, 6, 5, 6, 5, 6, 6, 5, 6, 6, 6, 6, 5, 6, 6, 6,\n",
       "       6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 6, 5, 6, 5, 6,\n",
       "       5, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 5, 6, 6, 5, 6, 7, 6, 6, 6, 5, 6,\n",
       "       5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 5, 6,\n",
       "       6, 6, 6, 5, 5, 6, 6, 6, 5, 6, 5, 5, 6, 6, 7, 6, 5, 6, 5, 5, 5, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 5, 5, 6, 6, 5, 5, 6, 5, 6, 6, 5, 6, 5, 5, 5,\n",
       "       5, 6, 6, 6, 5, 5, 6, 5, 6, 5, 6, 6, 6, 5, 6, 5, 6, 6, 5, 6, 6, 6,\n",
       "       6, 6, 5, 6, 6, 5, 5, 6, 6, 6, 6, 5, 6, 5, 5, 5, 5, 5, 6, 6, 6, 6,\n",
       "       6, 6, 6, 5, 5, 6, 6, 6, 6, 6, 7, 6, 5, 5, 6, 6, 6, 6, 6, 5, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 7, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6,\n",
       "       6, 6, 6, 6, 6, 5, 6, 6, 5, 6, 5, 5, 6, 5, 6, 5, 5, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 5, 5, 6, 5, 6, 6, 5, 6, 5, 5, 6, 5, 5, 6, 6, 5, 5, 6, 5,\n",
       "       5, 6, 6, 6, 6, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 5, 6, 6, 5, 5, 6, 5, 6, 6, 6,\n",
       "       6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 5, 7, 6, 6, 6, 6, 6, 5, 5, 6, 6, 6,\n",
       "       6, 6, 7, 6, 6, 6, 5, 6, 6, 7, 5, 6, 6, 6, 5, 6, 5, 5, 5, 6, 6, 6,\n",
       "       6, 6, 6, 5, 5, 6, 6, 6, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5,\n",
       "       6, 6, 6, 5, 6, 7, 5, 5, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5,\n",
       "       5, 6, 5, 6, 5, 5, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 5, 5, 6, 6, 6,\n",
       "       5, 6, 5, 5, 6, 6, 5, 5, 6, 6, 6, 5, 6, 6, 6, 5, 6, 6, 6, 6, 5, 6,\n",
       "       6, 6, 6, 5, 6, 6, 6, 5, 6, 6, 5, 5, 7, 6, 5, 6, 6, 5, 6, 6, 6, 6,\n",
       "       6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 6, 6, 6, 6,\n",
       "       5, 6, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 6, 6, 6, 5, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 5, 6, 5, 6,\n",
       "       6, 5, 5, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 7,\n",
       "       6, 6, 7, 6, 5, 5, 6, 6, 6, 5, 5, 6, 5, 5, 6, 6, 5, 7, 5, 6, 6, 5,\n",
       "       5, 6, 6, 6, 5, 5, 6, 6, 6, 6, 6, 6, 5, 6, 6, 5, 6, 5, 6, 5, 6, 6,\n",
       "       6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = LR.predict(X_test)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.00      0.00      0.00        25\n",
      "           5       0.58      0.53      0.55       291\n",
      "           6       0.50      0.80      0.61       432\n",
      "           7       0.62      0.07      0.12       192\n",
      "           8       0.00      0.00      0.00        35\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       980\n",
      "   macro avg       0.28      0.23      0.21       980\n",
      "weighted avg       0.51      0.52      0.46       980\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5224489795918368"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_similarity_score #highest accuracy yet\n",
    "jaccard_similarity_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine=GaussianNB()\n",
    "wine.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=wine.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4296734640591677"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, y_pred, average='weighted') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4387755102040816"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.14      0.40      0.21         5\n",
      "           4       0.23      0.24      0.24        25\n",
      "           5       0.51      0.53      0.52       291\n",
      "           6       0.52      0.33      0.41       432\n",
      "           7       0.35      0.64      0.45       192\n",
      "           8       0.00      0.00      0.00        35\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.44      0.44      0.44       980\n",
      "   macro avg       0.25      0.31      0.26       980\n",
      "weighted avg       0.46      0.44      0.43       980\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
